{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : C:\\Users\\MYPC\\DL_LAB\\FinalProject\\data\\D\\D_public.info\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading ./data/D\\D_train1.data\n",
      "=== Detected 55 Numerical Features\n",
      "=== Detected 17 Categorical Features\n",
      "=== Detected 0 Multi-valued Categorical Features\n",
      "=== Detected 4 Time Features\n",
      "=== 153042 Samples will be loaded \n",
      "========================\n",
      "=== Processing 4 Time features \n",
      "=== Processing 55 Numerical features \n",
      "=== Processing 17 Categorical features \n",
      "Replace missing values by 0 (slow, sorry)\n",
      "Loaded 153042 Samples and 59 Features\n",
      "[+] Success in  8.87 sec\n",
      "========= Reading ./data/D\\D_train1.solution\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  0.37 sec\n",
      "Info file found : C:\\Users\\MYPC\\DL_LAB\\FinalProject\\data\\D\\D_public.info\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading ./data/D\\D_test1.data\n",
      "=== Detected 55 Numerical Features\n",
      "=== Detected 17 Categorical Features\n",
      "=== Detected 0 Multi-valued Categorical Features\n",
      "=== Detected 4 Time Features\n",
      "=== 153124 Samples will be loaded \n",
      "========================\n",
      "=== Processing 4 Time features \n",
      "=== Processing 55 Numerical features \n",
      "=== Processing 17 Categorical features \n",
      "Replace missing values by 0 (slow, sorry)\n",
      "Loaded 153124 Samples and 59 Features\n",
      "[+] Success in  8.83 sec\n",
      "Info file found : C:\\Users\\MYPC\\DL_LAB\\FinalProject\\data\\D\\D_public.info\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading ./data/D\\D_feat.type\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading ./data/D\\D_test2.data\n",
      "=== Detected 55 Numerical Features\n",
      "=== Detected 17 Categorical Features\n",
      "=== Detected 0 Multi-valued Categorical Features\n",
      "=== Detected 4 Time Features\n",
      "=== 157852 Samples will be loaded \n",
      "========================\n",
      "=== Processing 4 Time features \n",
      "=== Processing 55 Numerical features \n",
      "=== Processing 17 Categorical features \n",
      "Replace missing values by 0 (slow, sorry)\n",
      "Loaded 157852 Samples and 59 Features\n",
      "[+] Success in  8.63 sec\n",
      "========= Reading ./data/D\\D_train1.solution\n",
      "[+] Success in  0.47 sec\n",
      "================================================================================\n",
      "Reading data finished.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.contrib.opt import AdamWOptimizer\n",
    "\n",
    "from data_manager import (\n",
    "    DataManager,\n",
    ")  # Note: you might need to install yaml via \"pip install pyyaml\"\n",
    "\n",
    "\n",
    "def normalized_validation_score(true, predicted):\n",
    "    # Normalize the area under the curve. A constant prediction will achieve an score of 0 whereas an oracle that predicts everything correct will have a score of 1.\n",
    "    return roc_auc_score(true, predicted) * 2 - 1\n",
    "\n",
    "def describe_categorical(x):\n",
    "    \"\"\"\n",
    "    Similar to describe but uses object data\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "    display(x[x.columns[x.dtypes == 'object']].describe())\n",
    "\n",
    "dataset = \"D\"\n",
    "input_dir = \"./data/\"\n",
    "D_train = DataManager(\n",
    "    dataset,\n",
    "    input_dir,\n",
    "    replace_missing=True,\n",
    "    max_samples=np.inf,\n",
    "    verbose=True,\n",
    "    testdata=0,\n",
    "    ltl=0,\n",
    ")\n",
    "D_valid = DataManager(\n",
    "    dataset,\n",
    "    input_dir,\n",
    "    replace_missing=True,\n",
    "    max_samples=np.inf,\n",
    "    verbose=True,\n",
    "    testdata=1,\n",
    "    ltl=0,\n",
    ")\n",
    "D_test = DataManager(\n",
    "    dataset,\n",
    "    input_dir,\n",
    "    replace_missing=True,\n",
    "    max_samples=np.inf,\n",
    "    verbose=True,\n",
    "    testdata=2,\n",
    "    ltl=0,\n",
    ")\n",
    "y_train0 = D_train.loadLabel(\n",
    "    os.path.join(input_dir, \"%s\" % dataset, \"%s_train1.solution\" % dataset)\n",
    ")\n",
    "\n",
    "solutions_file_valid = os.path.join(\n",
    "    input_dir, \"%s\" % dataset, \"%s_test%d.solution\" % (dataset, 1)\n",
    ")\n",
    "y_valid0 = np.loadtxt(solutions_file_valid)\n",
    "\n",
    "numericals = D_train.data[0][\"numerical\"]\n",
    "X_train0_categoricals = D_train.data[0][\"CAT\"]\n",
    "\n",
    "# To make things easier we will for now only use the numerical features and ignore the categorical\n",
    "\n",
    "X_train0 = numericals\n",
    "# X_train = np.concatenate((numericals, categoricals), axis=1)\n",
    "\n",
    "numericals = D_valid.data[0][\"numerical\"]\n",
    "X_valid0_categoricals = D_valid.data[0][\"CAT\"]\n",
    "\n",
    "X_valid0 = numericals\n",
    "# X_valid = np.concatenate((numericals, categoricals), axis=1)\n",
    "\n",
    "numericals = D_test.data[0][\"numerical\"]\n",
    "X_test0_categoricals = D_test.data[0][\"CAT\"]\n",
    "\n",
    "X_test0 = numericals\n",
    "# X_test = np.concatenate((numericals, categoricals), axis=1)\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"Reading data finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49374085e+09 1.46751662e+09 1.48253156e+09 ... 2.47500000e+02\n",
      "  5.00000000e-01 0.00000000e+00]\n",
      " [1.49374086e+09 0.00000000e+00 0.00000000e+00 ... 5.00000000e-01\n",
      "  5.00000000e-01 0.00000000e+00]\n",
      " [1.49374086e+09 0.00000000e+00 0.00000000e+00 ... 5.00000000e-01\n",
      "  5.00000000e-01 0.00000000e+00]\n",
      " ...\n",
      " [1.49389398e+09 0.00000000e+00 0.00000000e+00 ... 5.00000000e-01\n",
      "  5.00000000e-01 0.00000000e+00]\n",
      " [1.49391096e+09 1.47168616e+09 1.45329838e+09 ... 5.00000000e-01\n",
      "  5.00000000e-01 0.00000000e+00]\n",
      " [1.49391276e+09 1.47938606e+09 0.00000000e+00 ... 5.00000000e-01\n",
      "  5.00000000e-01 0.00000000e+00]]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X_train0, X_valid0))\n",
    "print(X)\n",
    "y = deepcopy(np.concatenate((y_train0.reshape(-1), y_valid0)))\n",
    "print(y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "y_cat = deepcopy(np.concatenate((y_train0.reshape(-1), y_valid0)))\n",
    "X_categoricals = np.concatenate((X_train0_categoricals, X_valid0_categoricals))\n",
    "X_train_categoricals, X_valid_categoricals, y_train_categoricals, y_valid_categoricals = train_test_split(X_categoricals, y_cat, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN -> Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\"name\": \"X\", \"TRAIN\": deepcopy(X_train), \"VALID\": deepcopy(X_valid), \"TEST\": deepcopy(X_test0), \"TRAIN_CAT\": deepcopy(X_train_categoricals),\"VALID_CAT\": deepcopy(X_valid_categoricals)}\n",
    "\n",
    "Y = {\"name\": \"Y\", \"TRAIN\": deepcopy(y_train), \"VALID\": deepcopy(y_valid),\"TRAIN_CAT\": deepcopy(y_train_categoricals), \"VALID_CAT\": deepcopy(y_valid_categoricals)}\n",
    "\n",
    "for S in [\"TRAIN\", \"VALID\", \"TEST\"]:\n",
    "    # to pandas DataFrame\n",
    "    tmp = pd.DataFrame(X[S]).apply(pd.to_numeric, errors=\"coerce\")\n",
    "    # replace all NaN values with mean.\n",
    "    X[S] = tmp.fillna(value=X[S].mean())\n",
    "    #print(X[\"name\"], S)\n",
    "    #print(X[S])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN (214316, 59)\n",
      "VALID (91850, 59)\n",
      "TEST (157852, 59)\n"
     ]
    }
   ],
   "source": [
    "for S in [\"TRAIN\", \"VALID\", \"TEST\"]:\n",
    "    for c in X[S]:\n",
    "        if X[S][c].std() != 0:\n",
    "            X[S][c] = (X[S][c] - X[S][c].mean()) / X[S][c].std()\n",
    "    #for c in X[S]:\n",
    "    #    print(c, pd.isnull(X[S][c]).all())\n",
    "    X[S] = X[S].values\n",
    "    print(S, X[S].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Validation data class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "TRAIN\n",
      "0.0    204017\n",
      "1.0     10299\n",
      "dtype: int64\n",
      "VALID\n",
      "0.0    87410\n",
      "1.0     4440\n",
      "dtype: int64\n",
      "\n",
      "Y\n",
      "TRAIN\n",
      "0.0    0.951945\n",
      "1.0    0.048055\n",
      "dtype: float64\n",
      "VALID\n",
      "0.0    0.95166\n",
      "1.0    0.04834\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_dist(d, sets, **kwargs):\n",
    "    print(d[\"name\"])\n",
    "    for s in sets:\n",
    "        print(s)\n",
    "        print(pd.value_counts(d[s], **kwargs))\n",
    "    print()\n",
    "\n",
    "data_dist(Y, [\"TRAIN\", \"VALID\"])\n",
    "data_dist(Y, [\"TRAIN\", \"VALID\"], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X[\"TRAIN\"])\n",
    "df_train_0 = df_train[Y[\"TRAIN\"] == 0]\n",
    "df_train_1 = df_train[Y[\"TRAIN\"] == 1]\n",
    "\n",
    "n_samples_train = 125000\n",
    "\n",
    "# upsampling minority class\n",
    "\"\"\"\n",
    "df_train_1_upsampled = resample(df_train_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=n_samples_train,    # to match majority class\n",
    "                                 random_state=123) \n",
    "\n",
    "X_trainC = pd.concat([df_train, df_train_1_upsampled]).values\n",
    "y_train2 = np.ones(n_samples_train,dtype=int).reshape((-1,1))\n",
    "y_trainC = pd.concat([pd.DataFrame(y_trainC),pd.DataFrame(y_train2)]).values\n",
    "\"\"\"\n",
    "\n",
    "# downsampling majority class\n",
    "df_train_0_downsampled = resample(\n",
    "    df_train_0,\n",
    "    replace=False,  # sample with replacement\n",
    "    n_samples=n_samples_train,  # to match majority class\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "X[\"TRAIN\"] = pd.concat([df_train_1, df_train_0_downsampled]).values\n",
    "Y[\"TRAIN\"] = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(np.ones(df_train_1.shape[0], dtype=int).reshape((-1, 1))),\n",
    "        pd.DataFrame(np.zeros(n_samples_train)),\n",
    "    ]\n",
    ").values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Validation data class distribution after downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "TRAIN\n",
      "0.0    0.92388\n",
      "1.0    0.07612\n",
      "dtype: float64\n",
      "VALID\n",
      "0.0    0.95166\n",
      "1.0    0.04834\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dist(Y, [\"TRAIN\", \"VALID\"], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of Training/Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19d5e203da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19d5c95f5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = []\n",
    "df = pd.DataFrame(X[\"TRAIN\"])\n",
    "dft = df.reindex(df.var().sort_values(ascending=False).index, axis=1)\n",
    "\n",
    "dfv = pd.DataFrame(X[\"VALID\"])\n",
    "dftest = pd.DataFrame(X[\"TEST\"])\n",
    "\n",
    "X[\"TRAIN_FILTERED\"] = df[dft.columns[0:46]].values\n",
    "X[\"VALID_FILTERED\"] = dfv[dft.columns[0:46]].values\n",
    "pd.DataFrame(X[\"TRAIN_FILTERED\"]).var().plot(label=\"x train filtered\", legend=True, grid=True)\n",
    "pd.DataFrame(X[\"VALID_FILTERED\"]).var().plot(label=\"x valid filtered\", legend=True, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\Pyro4\\util.py:839: UserWarning: msgpack serializer unavailable. requires msgpack 0.5.2+, found (0, 5, 1)\n",
      "  warnings.warn(\"msgpack serializer unavailable. requires msgpack 0.5.2+, found \" + str(msgpack.version))\n"
     ]
    }
   ],
   "source": [
    "import hpbandster.core.nameserver as hpns\n",
    "from hpbandster.optimizers import BOHB\n",
    "from hpbandster.optimizers import RandomSearch\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "from hpbandster.core.worker import Worker\n",
    "import argparse\n",
    "class MyWorker(Worker):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute(self, config, budget,**kwargs):\n",
    "        \"\"\"\n",
    "        Evaluates the configuration on the defined budget and returns the validation performance.\n",
    "        Args:\n",
    "            config: dictionary containing the sampled configurations by the optimizer\n",
    "            budget: (float) amount of time/epochs/etc. the model can use to train\n",
    "        Returns:\n",
    "            dictionary with mandatory fields:\n",
    "                'loss' (scalar)\n",
    "                'info' (dict)\n",
    "        \"\"\"\n",
    "        lr = config[\"learning_rate\"]\n",
    "        batch_size = config[\"batch_size\"]\n",
    "        epochs = budget\n",
    "        decay_rate = config[\"decay_rate\"]\n",
    "\n",
    "        # TODO: train and validate your convolutional neural networks here\n",
    "\n",
    "        \n",
    "        model = tf.keras.models.Sequential(\n",
    "                                          [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "                           ]\n",
    "                             )\n",
    "        optim = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate)\n",
    "            #bce = tf.keras.backend.binary_crossentropy(target, output, from_logits=True)\n",
    "\n",
    "        model.compile(optimizer=optim,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "        model.fit(X[\"TRAIN_FILTERED\"], Y[\"TRAIN\"], epochs=epochs, batch_size=batch_size)\n",
    "        val_score = model.evaluate(X[\"VALID_FILTERED\"], Y[\"VALID\"])\n",
    "        #validation_error=1-val_score[1]\n",
    "        \n",
    "        Y_HAT = model.predict(X[\"VALID_FILTERED\"])\n",
    "        auc=normalized_validation_score(Y[\"VALID\"], Y_HAT)\n",
    "        print(\"normalized_validation_score \", auc)\n",
    "        validation_error= -auc\n",
    "        \n",
    "\n",
    "        # TODO: We minimize so make sure you return the validation error here\n",
    "        return ({\n",
    "            'loss': validation_error,  # this is the a mandatory field to run hyperband\n",
    "            'info': {\n",
    "                        'validation accuracy': val_score[1]\n",
    "    \n",
    "                \n",
    "            }  # can be used for any user-defined information - also mandatory\n",
    "        })\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "        cs = CS.ConfigurationSpace()\n",
    "\n",
    "        lr = CSH.UniformFloatHyperparameter('learning_rate', lower=0.0001, upper=0.1, default_value='0.1', log=True)\n",
    "        decay_rate = CSH.UniformFloatHyperparameter('decay_rate', lower=0.0001, upper=0.1, default_value='0.001', log=True)\n",
    "        batch_size = CSH.UniformIntegerHyperparameter('batch_size', lower=10000, upper=30000, default_value=20000, log=True)\n",
    "        cs.add_hyperparameters([lr])\n",
    "        cs.add_hyperparameters([decay_rate])\n",
    "        cs.add_hyperparameters([batch_size])\n",
    "        \n",
    "        return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_incumbent(config,budget):\n",
    "    model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    optim = AdamWOptimizer(\n",
    "    weight_decay=config['decay_rate'], learning_rate=config['learning_rate'], beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "\n",
    "    model.compile(optimizer=optim,loss=\"binary_crossentropy\",metrics=[\"accuracy\", \"binary_crossentropy\"],)\n",
    "\n",
    "    model.fit(X[\"TRAIN_FILTERED\"], Y[\"TRAIN\"], epochs=budget, batch_size=config['batch_size'], shuffle=True)\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:48:17 wait_for_workers trying to get the condition\n",
      "11:48:17 DISPATCHER: started the 'discover_worker' thread\n",
      "11:48:17 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x19d060ee668; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "11:48:17 DISPATCHER: started the 'job_runner' thread\n",
      "11:48:17 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "11:48:17 WORKER: start listening for jobs\n",
      "11:48:17 DISPATCHER: Pyro daemon running on localhost:62173\n",
      "11:48:17 DISPATCHER: Starting worker discovery\n",
      "11:48:17 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "11:48:17 DISPATCHER: discovered new worker, hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:17 HBMASTER: number of workers changed to 1\n",
      "11:48:17 Enough workers to start this run!\n",
      "11:48:17 adjust_queue_size: lock accquired\n",
      "11:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:48:17 HBMASTER: starting run at 1548845297.7606313\n",
      "11:48:17 HBMASTER: adjusted queue size to (0, 1)\n",
      "11:48:17 DISPATCHER: Finished worker discovery\n",
      "11:48:17 HBMASTER: schedule new run for iteration 0\n",
      "11:48:17 DISPATCHER: Trying to submit another job.\n",
      "11:48:17 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "11:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:48:17 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "11:48:17 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "11:48:17 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:48:17 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "11:48:17 DISPATCHER: Trying to submit another job.\n",
      "11:48:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:48:17 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:17 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:48:17 WORKER: start processing job (0, 0, 0)\n",
      "11:48:17 WORKER: args: ()\n",
      "11:48:17 WORKER: kwargs: {'config': {'batch_size': 26500, 'decay_rate': 0.029490692981480177, 'learning_rate': 0.0028191856137346778}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "135299/135299 [==============================] - ETA: 0s - loss: 0.5426 - acc: 0.7524 - binary_crossentropy: 0.542 - 2s 12us/step - loss: 0.5383 - acc: 0.7560 - binary_crossentropy: 0.5383\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.3034 - acc: 0.9239 - binary_crossentropy: 0.3034\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2992 - acc: 0.9239 - binary_crossentropy: 0.2992\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2780 - acc: 0.9239 - binary_crossentropy: 0.2780\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2770 - acc: 0.9239 - binary_crossentropy: 0.2770\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2727 - acc: 0.9239 - binary_crossentropy: 0.2727\n",
      "91850/91850 [==============================] - 3s 35us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:48:30 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "11:48:30 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "11:48:30 DISPATCHER: job (0, 0, 0) finished\n",
      "11:48:30 DISPATCHER: register_result: lock acquired\n",
      "11:48:30 DISPATCHER: job (0, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:48:30 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 26500, 'decay_rate': 0.029490692981480177, 'learning_rate': 0.0028191856137346778}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.13839874681912212, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:48:30 job_callback for (0, 0, 0) started\n",
      "11:48:30 DISPATCHER: Trying to submit another job.\n",
      "11:48:30 job_callback for (0, 0, 0) got condition\n",
      "11:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:48:30 HBMASTER: Trying to run another job!\n",
      "11:48:30 job_callback for (0, 0, 0) finished\n",
      "11:48:30 HBMASTER: schedule new run for iteration 1\n",
      "11:48:30 HBMASTER: trying submitting job (1, 0, 0) to dispatcher\n",
      "11:48:30 HBMASTER: submitting job (1, 0, 0) to dispatcher\n",
      "11:48:30 DISPATCHER: trying to submit job (1, 0, 0)\n",
      "11:48:30 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:48:30 HBMASTER: job (1, 0, 0) submitted to dispatcher\n",
      "11:48:30 DISPATCHER: Trying to submit another job.\n",
      "11:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:48:30 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:30 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:30 WORKER: start processing job (1, 0, 0)\n",
      "11:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:48:30 WORKER: args: ()\n",
      "11:48:30 WORKER: kwargs: {'config': {'batch_size': 27868, 'decay_rate': 0.00013216510518612894, 'learning_rate': 0.0013636326354879305}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.13839874681912212\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 1s 11us/step - loss: 0.2703 - acc: 0.9239 - binary_crossentropy: 0.2703\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2694 - acc: 0.9239 - binary_crossentropy: 0.2694\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2681 - acc: 0.9239 - binary_crossentropy: 0.2681\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2672 - acc: 0.9239 - binary_crossentropy: 0.2672\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2667 - acc: 0.9239 - binary_crossentropy: 0.2667\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2662 - acc: 0.9239 - binary_crossentropy: 0.2662\n",
      "91850/91850 [==============================] - 3s 34us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:48:42 WORKER: done with job (1, 0, 0), trying to register it.\n",
      "11:48:42 WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "11:48:42 DISPATCHER: job (1, 0, 0) finished\n",
      "11:48:42 DISPATCHER: register_result: lock acquired\n",
      "11:48:42 DISPATCHER: job (1, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:48:42 job_id: (1, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 27868, 'decay_rate': 0.00013216510518612894, 'learning_rate': 0.0013636326354879305}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.19276204301773459, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:48:42 job_callback for (1, 0, 0) started\n",
      "11:48:42 DISPATCHER: Trying to submit another job.\n",
      "11:48:42 job_callback for (1, 0, 0) got condition\n",
      "11:48:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:48:42 HBMASTER: Trying to run another job!\n",
      "11:48:42 job_callback for (1, 0, 0) finished\n",
      "11:48:42 HBMASTER: schedule new run for iteration 2\n",
      "11:48:42 HBMASTER: trying submitting job (2, 0, 0) to dispatcher\n",
      "11:48:42 HBMASTER: submitting job (2, 0, 0) to dispatcher\n",
      "11:48:43 DISPATCHER: trying to submit job (2, 0, 0)\n",
      "11:48:43 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:48:43 HBMASTER: job (2, 0, 0) submitted to dispatcher\n",
      "11:48:43 DISPATCHER: Trying to submit another job.\n",
      "11:48:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:48:43 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:43 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:48:43 WORKER: start processing job (2, 0, 0)\n",
      "11:48:43 WORKER: args: ()\n",
      "11:48:43 WORKER: kwargs: {'config': {'batch_size': 10647, 'decay_rate': 0.007257522669159854, 'learning_rate': 0.0006899334801682543}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.19276204301773459\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 11us/step - loss: 0.2655 - acc: 0.9239 - binary_crossentropy: 0.2655\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2647 - acc: 0.9239 - binary_crossentropy: 0.2647\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2641 - acc: 0.9239 - binary_crossentropy: 0.2641\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2636 - acc: 0.9239 - binary_crossentropy: 0.2636\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2631 - acc: 0.9239 - binary_crossentropy: 0.2631\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2628 - acc: 0.9239 - binary_crossentropy: 0.2628\n",
      "91850/91850 [==============================] - 3s 37us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:48:55 WORKER: done with job (2, 0, 0), trying to register it.\n",
      "11:48:55 WORKER: registered result for job (2, 0, 0) with dispatcher\n",
      "11:48:55 DISPATCHER: job (2, 0, 0) finished\n",
      "11:48:56 DISPATCHER: register_result: lock acquired\n",
      "11:48:56 DISPATCHER: job (2, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:48:56 job_id: (2, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 10647, 'decay_rate': 0.007257522669159854, 'learning_rate': 0.0006899334801682543}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.22214790554196795, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:48:56 job_callback for (2, 0, 0) started\n",
      "11:48:56 DISPATCHER: Trying to submit another job.\n",
      "11:48:56 job_callback for (2, 0, 0) got condition\n",
      "11:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:48:56 HBMASTER: Trying to run another job!\n",
      "11:48:56 job_callback for (2, 0, 0) finished\n",
      "11:48:56 HBMASTER: schedule new run for iteration 3\n",
      "11:48:56 HBMASTER: trying submitting job (3, 0, 0) to dispatcher\n",
      "11:48:56 HBMASTER: submitting job (3, 0, 0) to dispatcher\n",
      "11:48:56 DISPATCHER: trying to submit job (3, 0, 0)\n",
      "11:48:56 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:48:56 HBMASTER: job (3, 0, 0) submitted to dispatcher\n",
      "11:48:56 DISPATCHER: Trying to submit another job.\n",
      "11:48:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:48:56 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:56 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:48:56 WORKER: start processing job (3, 0, 0)\n",
      "11:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:48:56 WORKER: args: ()\n",
      "11:48:56 WORKER: kwargs: {'config': {'batch_size': 23929, 'decay_rate': 0.0003360538469368812, 'learning_rate': 0.06329899528142081}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.22214790554196795\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 11us/step - loss: 0.2625 - acc: 0.9239 - binary_crossentropy: 0.2625\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2623 - acc: 0.9239 - binary_crossentropy: 0.2623\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2622 - acc: 0.9239 - binary_crossentropy: 0.2622\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2621 - acc: 0.9239 - binary_crossentropy: 0.2621\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2619 - acc: 0.9239 - binary_crossentropy: 0.2619\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2618 - acc: 0.9239 - binary_crossentropy: 0.2618\n",
      "91850/91850 [==============================] - 3s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:49:08 WORKER: done with job (3, 0, 0), trying to register it.\n",
      "11:49:08 WORKER: registered result for job (3, 0, 0) with dispatcher\n",
      "11:49:08 DISPATCHER: job (3, 0, 0) finished\n",
      "11:49:09 DISPATCHER: register_result: lock acquired\n",
      "11:49:09 DISPATCHER: job (3, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:49:09 job_id: (3, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 23929, 'decay_rate': 0.0003360538469368812, 'learning_rate': 0.06329899528142081}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.2290683055209426, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:49:09 job_callback for (3, 0, 0) started\n",
      "11:49:09 DISPATCHER: Trying to submit another job.\n",
      "11:49:09 job_callback for (3, 0, 0) got condition\n",
      "11:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:49:09 HBMASTER: Trying to run another job!\n",
      "11:49:09 job_callback for (3, 0, 0) finished\n",
      "11:49:09 HBMASTER: schedule new run for iteration 4\n",
      "11:49:09 HBMASTER: trying submitting job (4, 0, 0) to dispatcher\n",
      "11:49:09 HBMASTER: submitting job (4, 0, 0) to dispatcher\n",
      "11:49:09 DISPATCHER: trying to submit job (4, 0, 0)\n",
      "11:49:09 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:49:09 HBMASTER: job (4, 0, 0) submitted to dispatcher\n",
      "11:49:09 DISPATCHER: Trying to submit another job.\n",
      "11:49:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:49:09 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:09 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:09 WORKER: start processing job (4, 0, 0)\n",
      "11:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:49:09 WORKER: args: ()\n",
      "11:49:09 WORKER: kwargs: {'config': {'batch_size': 24694, 'decay_rate': 0.00029439952497866903, 'learning_rate': 0.003420350661316098}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.2290683055209426\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 1s 11us/step - loss: 0.2617 - acc: 0.9239 - binary_crossentropy: 0.2617\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2616 - acc: 0.9239 - binary_crossentropy: 0.2616\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2615 - acc: 0.9239 - binary_crossentropy: 0.2615\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2614 - acc: 0.9239 - binary_crossentropy: 0.2614\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2613 - acc: 0.9239 - binary_crossentropy: 0.2613\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2612 - acc: 0.9239 - binary_crossentropy: 0.2612\n",
      "38304/91850 [===========>..................] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:49:17 DISPATCHER: Starting worker discovery\n",
      "11:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "11:49:17 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91850/91850 [==============================] - 3s 38us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:49:21 WORKER: done with job (4, 0, 0), trying to register it.\n",
      "11:49:21 WORKER: registered result for job (4, 0, 0) with dispatcher\n",
      "11:49:21 DISPATCHER: job (4, 0, 0) finished\n",
      "11:49:21 DISPATCHER: register_result: lock acquired\n",
      "11:49:21 DISPATCHER: job (4, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:49:21 job_id: (4, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 24694, 'decay_rate': 0.00029439952497866903, 'learning_rate': 0.003420350661316098}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.23452608397208552, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:49:21 job_callback for (4, 0, 0) started\n",
      "11:49:21 DISPATCHER: Trying to submit another job.\n",
      "11:49:21 job_callback for (4, 0, 0) got condition\n",
      "11:49:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:49:21 HBMASTER: Trying to run another job!\n",
      "11:49:21 job_callback for (4, 0, 0) finished\n",
      "11:49:21 HBMASTER: schedule new run for iteration 5\n",
      "11:49:21 HBMASTER: trying submitting job (5, 0, 0) to dispatcher\n",
      "11:49:21 HBMASTER: submitting job (5, 0, 0) to dispatcher\n",
      "11:49:21 DISPATCHER: trying to submit job (5, 0, 0)\n",
      "11:49:21 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:49:21 HBMASTER: job (5, 0, 0) submitted to dispatcher\n",
      "11:49:21 DISPATCHER: Trying to submit another job.\n",
      "11:49:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:49:21 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:21 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:21 WORKER: start processing job (5, 0, 0)\n",
      "11:49:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:49:21 WORKER: args: ()\n",
      "11:49:21 WORKER: kwargs: {'config': {'batch_size': 15789, 'decay_rate': 0.0021475124451223316, 'learning_rate': 0.01246202815189295}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.23452608397208552\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 1s 11us/step - loss: 0.2611 - acc: 0.9239 - binary_crossentropy: 0.2611\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2609 - acc: 0.9239 - binary_crossentropy: 0.2609\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2608 - acc: 0.9239 - binary_crossentropy: 0.2608\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2607 - acc: 0.9239 - binary_crossentropy: 0.2607\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2605 - acc: 0.9239 - binary_crossentropy: 0.2605\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2604 - acc: 0.9239 - binary_crossentropy: 0.2604\n",
      "91850/91850 [==============================] - 3s 37us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:49:35 WORKER: done with job (5, 0, 0), trying to register it.\n",
      "11:49:35 WORKER: registered result for job (5, 0, 0) with dispatcher\n",
      "11:49:35 DISPATCHER: job (5, 0, 0) finished\n",
      "11:49:35 DISPATCHER: register_result: lock acquired\n",
      "11:49:35 DISPATCHER: job (5, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:49:35 job_id: (5, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 15789, 'decay_rate': 0.0021475124451223316, 'learning_rate': 0.01246202815189295}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.24022568129277877, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:49:35 job_callback for (5, 0, 0) started\n",
      "11:49:35 DISPATCHER: Trying to submit another job.\n",
      "11:49:35 job_callback for (5, 0, 0) got condition\n",
      "11:49:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:49:35 HBMASTER: Trying to run another job!\n",
      "11:49:35 job_callback for (5, 0, 0) finished\n",
      "11:49:35 HBMASTER: schedule new run for iteration 6\n",
      "11:49:35 HBMASTER: trying submitting job (6, 0, 0) to dispatcher\n",
      "11:49:35 HBMASTER: submitting job (6, 0, 0) to dispatcher\n",
      "11:49:35 DISPATCHER: trying to submit job (6, 0, 0)\n",
      "11:49:35 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:49:35 HBMASTER: job (6, 0, 0) submitted to dispatcher\n",
      "11:49:35 DISPATCHER: Trying to submit another job.\n",
      "11:49:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:49:35 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:35 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:35 WORKER: start processing job (6, 0, 0)\n",
      "11:49:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:49:35 WORKER: args: ()\n",
      "11:49:35 WORKER: kwargs: {'config': {'batch_size': 23616, 'decay_rate': 0.004580481248839686, 'learning_rate': 0.00505021889661801}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.24022568129277877\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 13us/step - loss: 0.2603 - acc: 0.9239 - binary_crossentropy: 0.2603\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2602 - acc: 0.9239 - binary_crossentropy: 0.2602\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9239 - binary_crossentropy: 0.2602\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2601 - acc: 0.9239 - binary_crossentropy: 0.2601\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2600 - acc: 0.9239 - binary_crossentropy: 0.2600\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2600 - acc: 0.9239 - binary_crossentropy: 0.2600\n",
      "91850/91850 [==============================] - 3s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:49:48 WORKER: done with job (6, 0, 0), trying to register it.\n",
      "11:49:48 WORKER: registered result for job (6, 0, 0) with dispatcher\n",
      "11:49:48 DISPATCHER: job (6, 0, 0) finished\n",
      "11:49:48 DISPATCHER: register_result: lock acquired\n",
      "11:49:48 DISPATCHER: job (6, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:49:48 job_id: (6, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 23616, 'decay_rate': 0.004580481248839686, 'learning_rate': 0.00505021889661801}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.2438492462259767, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:49:48 job_callback for (6, 0, 0) started\n",
      "11:49:48 DISPATCHER: Trying to submit another job.\n",
      "11:49:48 job_callback for (6, 0, 0) got condition\n",
      "11:49:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:49:48 HBMASTER: Trying to run another job!\n",
      "11:49:48 job_callback for (6, 0, 0) finished\n",
      "11:49:48 HBMASTER: schedule new run for iteration 7\n",
      "11:49:48 HBMASTER: trying submitting job (7, 0, 0) to dispatcher\n",
      "11:49:48 HBMASTER: submitting job (7, 0, 0) to dispatcher\n",
      "11:49:48 DISPATCHER: trying to submit job (7, 0, 0)\n",
      "11:49:48 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:49:48 HBMASTER: job (7, 0, 0) submitted to dispatcher\n",
      "11:49:48 DISPATCHER: Trying to submit another job.\n",
      "11:49:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:49:48 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:48 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:49:48 WORKER: start processing job (7, 0, 0)\n",
      "11:49:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:49:48 WORKER: args: ()\n",
      "11:49:48 WORKER: kwargs: {'config': {'batch_size': 29337, 'decay_rate': 0.012618776970541236, 'learning_rate': 0.00010758850935051268}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.2438492462259767\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 11us/step - loss: 0.2599 - acc: 0.9239 - binary_crossentropy: 0.2599\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2599 - acc: 0.9239 - binary_crossentropy: 0.2599\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2598 - acc: 0.9239 - binary_crossentropy: 0.2598\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2598 - acc: 0.9239 - binary_crossentropy: 0.2598\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2597 - acc: 0.9239 - binary_crossentropy: 0.2597\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2597 - acc: 0.9239 - binary_crossentropy: 0.2597\n",
      "91850/91850 [==============================] - 3s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50:01 WORKER: done with job (7, 0, 0), trying to register it.\n",
      "11:50:01 WORKER: registered result for job (7, 0, 0) with dispatcher\n",
      "11:50:01 DISPATCHER: job (7, 0, 0) finished\n",
      "11:50:01 DISPATCHER: register_result: lock acquired\n",
      "11:50:01 DISPATCHER: job (7, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:50:01 job_id: (7, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 29337, 'decay_rate': 0.012618776970541236, 'learning_rate': 0.00010758850935051268}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.24605762838688117, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:50:01 job_callback for (7, 0, 0) started\n",
      "11:50:01 job_callback for (7, 0, 0) got condition\n",
      "11:50:01 DISPATCHER: Trying to submit another job.\n",
      "11:50:01 HBMASTER: Trying to run another job!\n",
      "11:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:50:01 job_callback for (7, 0, 0) finished\n",
      "11:50:01 HBMASTER: schedule new run for iteration 8\n",
      "11:50:01 HBMASTER: trying submitting job (8, 0, 0) to dispatcher\n",
      "11:50:01 HBMASTER: submitting job (8, 0, 0) to dispatcher\n",
      "11:50:01 DISPATCHER: trying to submit job (8, 0, 0)\n",
      "11:50:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:50:01 HBMASTER: job (8, 0, 0) submitted to dispatcher\n",
      "11:50:01 DISPATCHER: Trying to submit another job.\n",
      "11:50:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:50:01 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:50:01 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:50:01 WORKER: start processing job (8, 0, 0)\n",
      "11:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:50:01 WORKER: args: ()\n",
      "11:50:01 WORKER: kwargs: {'config': {'batch_size': 11219, 'decay_rate': 0.006705644403166464, 'learning_rate': 0.00043069286567656064}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.24605762838688117\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 11us/step - loss: 0.2596 - acc: 0.9239 - binary_crossentropy: 0.2596\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2595 - acc: 0.9239 - binary_crossentropy: 0.2595\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2594 - acc: 0.9239 - binary_crossentropy: 0.2594\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2593 - acc: 0.9239 - binary_crossentropy: 0.2593\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2592 - acc: 0.9239 - binary_crossentropy: 0.2592\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2591 - acc: 0.9239 - binary_crossentropy: 0.2591\n",
      "91850/91850 [==============================] - 3s 37us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50:14 WORKER: done with job (8, 0, 0), trying to register it.\n",
      "11:50:14 WORKER: registered result for job (8, 0, 0) with dispatcher\n",
      "11:50:14 DISPATCHER: job (8, 0, 0) finished\n",
      "11:50:14 DISPATCHER: register_result: lock acquired\n",
      "11:50:14 DISPATCHER: job (8, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:50:14 job_id: (8, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 11219, 'decay_rate': 0.006705644403166464, 'learning_rate': 0.00043069286567656064}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.25042555740731, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:50:14 job_callback for (8, 0, 0) started\n",
      "11:50:14 DISPATCHER: Trying to submit another job.\n",
      "11:50:14 job_callback for (8, 0, 0) got condition\n",
      "11:50:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:50:14 HBMASTER: Trying to run another job!\n",
      "11:50:14 job_callback for (8, 0, 0) finished\n",
      "11:50:14 HBMASTER: schedule new run for iteration 9\n",
      "11:50:14 HBMASTER: trying submitting job (9, 0, 0) to dispatcher\n",
      "11:50:14 HBMASTER: submitting job (9, 0, 0) to dispatcher\n",
      "11:50:14 DISPATCHER: trying to submit job (9, 0, 0)\n",
      "11:50:14 DISPATCHER: trying to notify the job_runner thread.\n",
      "11:50:14 HBMASTER: job (9, 0, 0) submitted to dispatcher\n",
      "11:50:14 DISPATCHER: Trying to submit another job.\n",
      "11:50:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "11:50:14 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:50:14 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832\n",
      "11:50:14 WORKER: start processing job (9, 0, 0)\n",
      "11:50:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "11:50:14 WORKER: args: ()\n",
      "11:50:14 WORKER: kwargs: {'config': {'batch_size': 16032, 'decay_rate': 0.000509315269448498, 'learning_rate': 0.06939427967464006}, 'budget': 6, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.25042555740731\n",
      "Epoch 1/6\n",
      "112224/135299 [=======================>......] - ETA: 0s - loss: 0.2579 - acc: 0.9244 - binary_crossentropy: 0.2579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50:17 DISPATCHER: Starting worker discovery\n",
      "11:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "11:50:17 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135299/135299 [==============================] - 1s 11us/step - loss: 0.2591 - acc: 0.9239 - binary_crossentropy: 0.2591\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2590 - acc: 0.9239 - binary_crossentropy: 0.2590\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2589 - acc: 0.9239 - binary_crossentropy: 0.2589\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2588 - acc: 0.9239 - binary_crossentropy: 0.2588\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2588 - acc: 0.9239 - binary_crossentropy: 0.2588\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2587 - acc: 0.9239 - binary_crossentropy: 0.2587\n",
      "91850/91850 [==============================] - 3s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50:27 WORKER: done with job (9, 0, 0), trying to register it.\n",
      "11:50:27 WORKER: registered result for job (9, 0, 0) with dispatcher\n",
      "11:50:27 DISPATCHER: job (9, 0, 0) finished\n",
      "11:50:27 DISPATCHER: register_result: lock acquired\n",
      "11:50:27 DISPATCHER: job (9, 0, 0) on hpbandster.run_example1.worker.DESKTOP-HNPU7LV.756022832 finished\n",
      "11:50:27 job_id: (9, 0, 0)\n",
      "kwargs: {'config': {'batch_size': 16032, 'decay_rate': 0.000509315269448498, 'learning_rate': 0.06939427967464006}, 'budget': 6, 'working_directory': '.'}\n",
      "result: {'loss': -0.2530328054286983, 'info': {'validation accuracy': 0.9516603157295763}}\n",
      "exception: None\n",
      "\n",
      "11:50:27 job_callback for (9, 0, 0) started\n",
      "11:50:27 DISPATCHER: Trying to submit another job.\n",
      "11:50:27 job_callback for (9, 0, 0) got condition\n",
      "11:50:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "11:50:27 HBMASTER: Trying to run another job!\n",
      "11:50:27 job_callback for (9, 0, 0) finished\n",
      "11:50:27 HBMASTER: shutdown initiated, shutdown_workers = True\n",
      "11:50:27 WORKER: shutting down now!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_validation_score  0.2530328054286983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50:27 DISPATCHER: Dispatcher shutting down\n",
      "11:50:27 DISPATCHER: Trying to submit another job.\n",
      "11:50:27 DISPATCHER: job_runner shutting down\n",
      "11:50:27 DISPATCHER: discover_workers shutting down\n",
      "11:50:27 DISPATCHER: 'discover_worker' thread exited\n",
      "11:50:27 DISPATCHER: 'job_runner' thread exited\n",
      "11:50:27 DISPATCHER: shut down complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found configuration: {'batch_size': 16032, 'decay_rate': 0.000509315269448498, 'learning_rate': 0.06939427967464006}\n",
      "Epoch 1/6\n",
      "135299/135299 [==============================] - 2s 11us/step - loss: 0.2587 - acc: 0.9239 - binary_crossentropy: 0.2587\n",
      "Epoch 2/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2586 - acc: 0.9239 - binary_crossentropy: 0.2586\n",
      "Epoch 3/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2585 - acc: 0.9239 - binary_crossentropy: 0.2585\n",
      "Epoch 4/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2585 - acc: 0.9239 - binary_crossentropy: 0.2585\n",
      "Epoch 5/6\n",
      "135299/135299 [==============================] - 1s 6us/step - loss: 0.2585 - acc: 0.9239 - binary_crossentropy: 0.2585\n",
      "Epoch 6/6\n",
      "135299/135299 [==============================] - 1s 7us/step - loss: 0.2584 - acc: 0.9239 - binary_crossentropy: 0.2584\n"
     ]
    }
   ],
   "source": [
    "NS = hpns.NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
    "NS.start()\n",
    "\n",
    "w = MyWorker(nameserver='127.0.0.1', run_id='example1')\n",
    "w.run(background=True)\n",
    "\n",
    "rs = RandomSearch(configspace=w.get_configspace(),\n",
    "                  run_id='example1', nameserver='127.0.0.1',\n",
    "                  min_budget=int(6), max_budget=int(6))\n",
    "res = rs.run(n_iterations=10)\n",
    "\n",
    "rs.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()\n",
    "\n",
    "id2config = res.get_id2config_mapping()\n",
    "incumbent = res.get_incumbent_id()\n",
    "\n",
    "print('Best found configuration:', id2config[incumbent]['config'])\n",
    "\n",
    "model = train_incumbent(config=id2config[incumbent]['config'],budget=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'model = tf.keras.models.Sequential(\\n    [\\n        tf.keras.layers.Flatten(),\\n        tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(59,)),\\n        tf.keras.layers.Dropout(0.2),\\n        tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(59,)),\\n        tf.keras.layers.Dropout(0.3),\\n        tf.keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(59,)),\\n        tf.keras.layers.Dropout(0.4),\\n        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\\n    ]\\n)\\n\\n# optim = tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\\noptim = AdamWOptimizer(\\n    weight_decay=0.001, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-08\\n)\\n# bce = tf.keras.backend.binary_crossentropy(target, output, from_logits=True)\\n\\nmodel.compile(\\n    optimizer=optim,\\n    loss=\"binary_crossentropy\",\\n    metrics=[\"accuracy\", \"binary_crossentropy\"],\\n)\\n\\nmodel.fit(X[\"TRAIN_FILTERED\"], Y[\"TRAIN\"], epochs=40, batch_size=20000, shuffle=True)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(59,)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# optim = tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "optim = AdamWOptimizer(\n",
    "    weight_decay=0.001, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-08\n",
    ")\n",
    "# bce = tf.keras.backend.binary_crossentropy(target, output, from_logits=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", \"binary_crossentropy\"],\n",
    ")\n",
    "\n",
    "model.fit(X[\"TRAIN_FILTERED\"], Y[\"TRAIN\"], epochs=40, batch_size=20000, shuffle=True)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91850/91850 [==============================] - 3s 34us/step\n",
      "loss 0.19511235330892635\n",
      "acc 0.9516494284132997\n",
      "binary_crossentropy 0.19511235330892635\n",
      "normalized_validation_score  0.25532134210632096\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X[\"VALID_FILTERED\"], Y[\"VALID\"])\n",
    "for i, m in enumerate(model.metrics_names):\n",
    "    print(m, res[i])\n",
    "\n",
    "Y_HAT = model.predict(X[\"VALID_FILTERED\"])\n",
    "print(\"normalized_validation_score \", normalized_validation_score(Y[\"VALID\"], Y_HAT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "      <td>127002</td>\n",
       "      <td>127006</td>\n",
       "      <td>80134</td>\n",
       "      <td>127002</td>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "      <td>134022</td>\n",
       "      <td>134015</td>\n",
       "      <td>73744</td>\n",
       "      <td>134022</td>\n",
       "      <td>214316</td>\n",
       "      <td>214316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14244</td>\n",
       "      <td>8358</td>\n",
       "      <td>48347</td>\n",
       "      <td>214313</td>\n",
       "      <td>2</td>\n",
       "      <td>541</td>\n",
       "      <td>527</td>\n",
       "      <td>343</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>828</td>\n",
       "      <td>703</td>\n",
       "      <td>365</td>\n",
       "      <td>192</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2985445252451961379</td>\n",
       "      <td>14475392532262432119</td>\n",
       "      <td>15072482018280671789</td>\n",
       "      <td>7713461017225751774</td>\n",
       "      <td>14771401151246747869</td>\n",
       "      <td>7638001807695707609</td>\n",
       "      <td>6220772307398391706</td>\n",
       "      <td>13871198517152104089</td>\n",
       "      <td>5656685945142785391</td>\n",
       "      <td>6843963171864976598</td>\n",
       "      <td>14771401151246747869</td>\n",
       "      <td>7265916326799606203</td>\n",
       "      <td>6220772307398391706</td>\n",
       "      <td>13871198517152104089</td>\n",
       "      <td>5656685945142785391</td>\n",
       "      <td>6843963171864976598</td>\n",
       "      <td>6843963171864976598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>676</td>\n",
       "      <td>1078</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>111046</td>\n",
       "      <td>11062</td>\n",
       "      <td>5112</td>\n",
       "      <td>5199</td>\n",
       "      <td>50225</td>\n",
       "      <td>181605</td>\n",
       "      <td>189566</td>\n",
       "      <td>9303</td>\n",
       "      <td>5948</td>\n",
       "      <td>3531</td>\n",
       "      <td>27790</td>\n",
       "      <td>162816</td>\n",
       "      <td>214316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                     1                     2   \\\n",
       "count                214316                214316                214316   \n",
       "unique                14244                  8358                 48347   \n",
       "top     2985445252451961379  14475392532262432119  15072482018280671789   \n",
       "freq                    676                  1078                   132   \n",
       "\n",
       "                         3                     4                    5   \\\n",
       "count                214316                214316               127002   \n",
       "unique               214313                     2                  541   \n",
       "top     7713461017225751774  14771401151246747869  7638001807695707609   \n",
       "freq                      2                111046                11062   \n",
       "\n",
       "                         6                     7                    8   \\\n",
       "count                127006                 80134               127002   \n",
       "unique                  527                   343                  121   \n",
       "top     6220772307398391706  13871198517152104089  5656685945142785391   \n",
       "freq                   5112                  5199                50225   \n",
       "\n",
       "                         9                     10                   11  \\\n",
       "count                214316                214316               134022   \n",
       "unique                    4                     3                  828   \n",
       "top     6843963171864976598  14771401151246747869  7265916326799606203   \n",
       "freq                 181605                189566                 9303   \n",
       "\n",
       "                         12                    13                   14  \\\n",
       "count                134015                 73744               134022   \n",
       "unique                  703                   365                  192   \n",
       "top     6220772307398391706  13871198517152104089  5656685945142785391   \n",
       "freq                   5948                  3531                27790   \n",
       "\n",
       "                         15                   16  \n",
       "count                214316               214316  \n",
       "unique                   31                    1  \n",
       "top     6843963171864976598  6843963171864976598  \n",
       "freq                 162816               214316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "      <td>54419</td>\n",
       "      <td>54419</td>\n",
       "      <td>34414</td>\n",
       "      <td>54419</td>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "      <td>57526</td>\n",
       "      <td>57524</td>\n",
       "      <td>31771</td>\n",
       "      <td>57526</td>\n",
       "      <td>91850</td>\n",
       "      <td>91850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11621</td>\n",
       "      <td>7033</td>\n",
       "      <td>34603</td>\n",
       "      <td>91850</td>\n",
       "      <td>3</td>\n",
       "      <td>509</td>\n",
       "      <td>513</td>\n",
       "      <td>333</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>773</td>\n",
       "      <td>639</td>\n",
       "      <td>356</td>\n",
       "      <td>176</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3279021083640072691</td>\n",
       "      <td>14475392532262432119</td>\n",
       "      <td>15072482018280671789</td>\n",
       "      <td>16665491600719736855</td>\n",
       "      <td>14771401151246747869</td>\n",
       "      <td>7638001807695707609</td>\n",
       "      <td>6220772307398391706</td>\n",
       "      <td>13871198517152104089</td>\n",
       "      <td>5656685945142785391</td>\n",
       "      <td>6843963171864976598</td>\n",
       "      <td>14771401151246747869</td>\n",
       "      <td>7265916326799606203</td>\n",
       "      <td>6220772307398391706</td>\n",
       "      <td>13871198517152104089</td>\n",
       "      <td>5656685945142785391</td>\n",
       "      <td>6843963171864976598</td>\n",
       "      <td>6843963171864976598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>286</td>\n",
       "      <td>449</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>47588</td>\n",
       "      <td>4807</td>\n",
       "      <td>2200</td>\n",
       "      <td>2260</td>\n",
       "      <td>21561</td>\n",
       "      <td>77780</td>\n",
       "      <td>81180</td>\n",
       "      <td>4049</td>\n",
       "      <td>2681</td>\n",
       "      <td>1535</td>\n",
       "      <td>11887</td>\n",
       "      <td>69593</td>\n",
       "      <td>91850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                     1                     2   \\\n",
       "count                 91850                 91850                 91850   \n",
       "unique                11621                  7033                 34603   \n",
       "top     3279021083640072691  14475392532262432119  15072482018280671789   \n",
       "freq                    286                   449                    59   \n",
       "\n",
       "                          3                     4                    5   \\\n",
       "count                  91850                 91850                54419   \n",
       "unique                 91850                     3                  509   \n",
       "top     16665491600719736855  14771401151246747869  7638001807695707609   \n",
       "freq                       1                 47588                 4807   \n",
       "\n",
       "                         6                     7                    8   \\\n",
       "count                 54419                 34414                54419   \n",
       "unique                  513                   333                  110   \n",
       "top     6220772307398391706  13871198517152104089  5656685945142785391   \n",
       "freq                   2200                  2260                21561   \n",
       "\n",
       "                         9                     10                   11  \\\n",
       "count                 91850                 91850                57526   \n",
       "unique                    4                     3                  773   \n",
       "top     6843963171864976598  14771401151246747869  7265916326799606203   \n",
       "freq                  77780                 81180                 4049   \n",
       "\n",
       "                         12                    13                   14  \\\n",
       "count                 57524                 31771                57526   \n",
       "unique                  639                   356                  176   \n",
       "top     6220772307398391706  13871198517152104089  5656685945142785391   \n",
       "freq                   2681                  1535                11887   \n",
       "\n",
       "                         15                   16  \n",
       "count                 91850                91850  \n",
       "unique                   30                    1  \n",
       "top     6843963171864976598  6843963171864976598  \n",
       "freq                  69593                91850  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(X[\"TRAIN_CAT\"])\n",
    "df_valid = pd.DataFrame(X[\"VALID_CAT\"])\n",
    "\n",
    "print(df_train.columns.values)\n",
    "print(df_valid.columns.values)\n",
    "\n",
    "describe_categorical(df_train)\n",
    "describe_categorical(df_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droping Unimportant Categorical Features and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([4,7,8,9,10,13,14,15,16],axis=1,inplace=True)\n",
    "df_valid.drop([4,7,8,9,10,13,14,15,16],axis=1,inplace=True)\n",
    "\n",
    "for var in df_train:\n",
    "    df_train[var].fillna(0, inplace=True)\n",
    "\n",
    "for var in df_valid:\n",
    "    df_valid[var].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Random Forest to Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "rf.fit(df_train.values, Y[\"TRAIN_CAT\"])\n",
    "pred_valid = rf.predict(df_valid.values)\n",
    "#print(pred_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "rf = BaggingRegressor(n_estimators = 300, random_state = 42)\n",
    "rf.fit(df_train.values, Y[\"TRAIN_CAT\"])\n",
    "pred_valid = rf.predict(df_valid.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'features_list = df_train.columns.values\\nfeature_importance = rf.feature_importances_\\nsorted_idx = np.argsort(feature_importance)[:20]\\n\\nplt.figure(figsize=(5,7))\\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\\nplt.xlabel('Importance')\\nplt.title('Feature importances')\\nplt.draw()\\nplt.show()\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''features_list = df_train.columns.values\n",
    "feature_importance = rf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature importances')\n",
    "plt.draw()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30691067053782994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_validation_score(Y[\"VALID_CAT\"],pred_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Evaluation of Feed Forward Neural Network and Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combined = (pred_valid.reshape(-1,1)+ Y_HAT.reshape(-1,1))/2\n",
    "normalized_validation_score(Y[\"VALID\"],y_pred_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
